{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ML model using scikit-learn\n",
    "\n",
    "In this notebook, we create a sample  Logistic Regression model using scikit-learn, and save the model to disk using Python's built in persistence model (pickle)\n",
    "\n",
    "For this tutorial we will be working with a small subset of Airline Data from BTS (http://www.transtats.bts.gov). The sample data here is cleaned, and has only 4 columns. For actual predictions (with all the available columns), the whole dataset can be easily downloaded from the above link. We'll be trying to predict a classification- delay or no delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the data into a pandas Dataframe\n",
    "df = pd.read_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our sample data, we have data about airline delays, with the following columns: \n",
    "* ORIGIN (Origin Airport)\n",
    "* DEST (Destination Airport)\n",
    "* UNIQUE_CARRIER (Airline  Carrier)\n",
    "* DAY_OF_WEEK (Day of the Week)\n",
    "* DEP_HOUR (Hour of Departure)\n",
    "* ARR_DELAY (Arrival Delay in minutes)\n",
    "\n",
    "We will build a model to predict whether a flight is delayed more than 5 minutes or not, given the ORIGIN, DEST and UNIQUE_CARRIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, we transform ARR_DELAY into a 1/0 format for Delay/No Delay\n",
    "# For this we are going to use the Python Lambda function on the dataframe\n",
    "\n",
    "df['ARR_DELAY'] = df['ARR_DELAY'].apply(lambda x:1 if x>=5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='ARR_DELAY', data=df,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert Categorical Variables into Dummy Variables\n",
    "df = pd.concat([df,pd.get_dummies(df['UNIQUE_CARRIER'],drop_first=True,prefix=\"UNIQUE_CARRIER\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['ORIGIN'],drop_first=True,prefix=\"ORIGIN\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DEST'],drop_first=True,prefix=\"DEST\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DAY_OF_WEEK'],drop_first=True,prefix=\"DAY_OF_WEEK\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DEP_HOUR'],drop_first=True,prefix=\"DEP_HOUR\")],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the original Categorical Variables\n",
    "df.drop(['ORIGIN','DEST','UNIQUE_CARRIER','DAY_OF_WEEK','DEP_HOUR'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('ARR_DELAY',axis=1), \n",
    "                                                    df['ARR_DELAY'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Train the model\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "#Predicting on the Test Set\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an overall accuracy of 0.61, which is not too bad given the limited dataset on which we trained the model. We will not try to improve on the model here, as that is not the objective of this tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logmodel.pkl', 'wb') as fid:\n",
    "    pickle.dump(logmodel, fid,2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save a dictionary of the index keys to make the dummy variables out of user input\n",
    "\n",
    "#create a dataframe containing only the categorical variables. In our case, it is the entire dataset except the ARR_DELAY column\n",
    "cat = df.drop('ARR_DELAY',axis=1)\n",
    "index_dict = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "#Save the index_dict into disk\n",
    "with open('cat', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid,2)  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
